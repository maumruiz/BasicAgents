{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize all the libraries which are necessary.\n",
    "\n",
    "Some of the classes imported are the following:\n",
    "<ul>\n",
    "    <li><b>FullyObservableEnvironment:</b></li>\n",
    "        &emsp; This class contains the type of environment where you can perceive all places where there are Golds and Traps. All other relevant portions of the environment are also visible.\n",
    "    <li><b>PartiallyObservableEnvironment:</b></li>\n",
    "        &emsp; In this type of environment some states are hidden, that means, the agent(s) can never see the entire state of the environment. This kind of environment needs agents with memory to be solved.\n",
    "    <li><b>ReflexAgent:</b></li>\n",
    "        &emsp; This class implements the Simple Reflex Agents which acts only on basis of the percepts that the agents receives from the environment. It's actions are based on condition-action rules.\n",
    "    <li><b>ModelBasedAgent:</b></li>\n",
    "        &emsp; This is the kind of agents which maintains the structure that describes the part of the world which cannot see. This knowledge is what is called model of the world.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from FullyObservableEnvironment import FullyObservableEnvironment\n",
    "from PartiallyObservableEnvironment import PartiallyObservableEnvironment\n",
    "from ReflexAgent import ReflexAgent\n",
    "from ModelBasedAgent import ModelBasedAgent\n",
    "from Objects import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Partially Observable Environment</b></h1>\n",
    "\n",
    "The first Agent to be tested is the Reflex Agent in a Partially Observable Environment.\n",
    "In addition to the agent, we also add 5 pieces of gold and 6 traps in specified positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Initial State\n",
      "---------------------------\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (U - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (U - 3) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "Agent state: (3, 1, UP)\n",
      "Agent performance: 100\n",
      "\n",
      "---------------------------\n",
      "Run details\n",
      "---------------------------\n",
      "<STEP 1>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 1, RIGHT)\n",
      "Agent performance: 94\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (R - 2) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (R - 2) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "<STEP 2>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 1, DOWN)\n",
      "Agent performance: 88\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (D - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (D - 1) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "<STEP 3>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 1, DOWN)\n",
      "Agent performance: 87\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (D - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - 1) (- - -) \n",
      "(- 1 -) (D - -) (- - -) \n",
      "\n",
      "\n",
      "<STEP 4>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 1, LEFT)\n",
      "Agent performance: 86\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (L - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - 1) (- - -) \n",
      "(- 1 -) (L - -) (- - -) \n",
      "\n",
      "\n",
      "<STEP 5>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 0, LEFT)\n",
      "Agent performance: 95\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (L - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - 1) \n",
      "(L - -) (- - -) \n",
      "\n",
      "\n",
      "<STEP 6>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 0, UP)\n",
      "Agent performance: 94\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (U - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - 1) \n",
      "(U - -) (- - -) \n",
      "\n",
      "\n",
      "<STEP 7>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 0, UP)\n",
      "Agent performance: 93\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (U - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(U - -) (- - 1) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 8>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 0, UP)\n",
      "Agent performance: 92\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (U - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - 1) (- - -) \n",
      "(U - -) (- - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "<STEP 9>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 0, UP)\n",
      "Agent performance: 86\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (U - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- 1 -) \n",
      "(U - -) (- - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 10>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 0, UP)\n",
      "Agent performance: 85\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (U - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(U - -) (- 1 -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 11>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 0, RIGHT)\n",
      "Agent performance: 84\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (R - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(R - -) (- 1 -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 12>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 1, RIGHT)\n",
      "Agent performance: 93\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (R - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (R - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "<STEP 13>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 2, RIGHT)\n",
      "Agent performance: 92\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (R - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (R - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "<STEP 14>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 3, RIGHT)\n",
      "Agent performance: 91\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (R - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (R - -) (- - -) \n",
      "(- - -) (- - -) (- 2 -) \n",
      "\n",
      "<STEP 15>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 4, RIGHT)\n",
      "Agent performance: 90\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (R - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (R - -) \n",
      "(- - -) (- 2 -) \n",
      "\n",
      "<STEP 16>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 4, DOWN)\n",
      "Agent performance: 89\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (D - -) \n",
      "(- - -) (- 2 -) \n",
      "\n",
      "<STEP 17>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 4, DOWN)\n",
      "Agent performance: 98\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (D 1 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (D 1 -) \n",
      "(- 1 1) (- - -) \n",
      "\n",
      "<STEP 18>\n",
      "SELECTED ACTION:  STAY\n",
      "Agent state:  (1, 4, DOWN)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (D - -) \n",
      "(- 1 1) (- - -) \n",
      "\n",
      "<STEP 19>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 4, DOWN)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (D - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- 1 1) (D - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 20>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 4, LEFT)\n",
      "Agent performance: 106\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (L - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- 1 1) (L - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "<STEP 21>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 3, LEFT)\n",
      "Agent performance: 110\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (L - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (L - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment = PartiallyObservableEnvironment()\n",
    "\n",
    "reflex_agent = ReflexAgent()\n",
    "environment.add_thing(reflex_agent)\n",
    "\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (4,0))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (0,1))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (2,3))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (1,0))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (2,3))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (4,4))\n",
    "\n",
    "# for _ in range(10):\n",
    "#     trap = Trap()\n",
    "#     environment.add_thing(trap)    \n",
    "\n",
    "# print('---------------------------')\n",
    "# print('Initial State of Environment')\n",
    "# print('---------------------------')\n",
    "# print(\"Agent state: %s\" % agent)\n",
    "# print(\"Agent performance: %s\" % agent.performance)\n",
    "# print('')\n",
    "# print('Environment:')\n",
    "# print(environment)\n",
    "\n",
    "environment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second agent in the Partially Observable Environment is the Model Based Agent which will be tested with gold and traps at the same positions as the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Initial State\n",
      "---------------------------\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (R - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- 1 1) (- - -) \n",
      "(- - -) (R - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- 1 1) (- - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (V - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (- - 1) \n",
      "\n",
      "Agent state: (3, 4, RIGHT)\n",
      "Agent performance: 100\n",
      "\n",
      "---------------------------\n",
      "Run details\n",
      "---------------------------\n",
      "<STEP 1>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 4, DOWN)\n",
      "Agent performance: 99\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (D - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- 1 1) (- - -) \n",
      "(- - -) (D - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- 1 1) (- - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (V - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (- - 1) \n",
      "\n",
      "<STEP 2>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 4, LEFT)\n",
      "Agent performance: 98\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (L - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- 1 1) (- - -) \n",
      "(- - -) (L - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- 1 1) (- - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (V - -) \n",
      "(? ? ?) (? ? ?) (? ? ?) (- - -) (- - 1) \n",
      "\n",
      "<STEP 3>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 3, LEFT)\n",
      "Agent performance: 97\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (L - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- 1 1) (- - -) \n",
      "(- - -) (L - -) (- - -) \n",
      "(- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (- - -) (- 1 1) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 4>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 3, UP)\n",
      "Agent performance: 96\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (U - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- 1 1) (- - -) \n",
      "(- - -) (U - -) (- - -) \n",
      "(- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (- - -) (- 1 1) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 5>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 3, UP)\n",
      "Agent performance: 100\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (U - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- 2 -) \n",
      "(- - -) (U - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (? ? ?) (? ? ?) (? ? ?) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- 2 -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 6>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 3, UP)\n",
      "Agent performance: 99\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (U - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (U - -) (- 2 -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- 2 -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 7>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 3, RIGHT)\n",
      "Agent performance: 98\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (R - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (R - -) (- 2 -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- 2 -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 8>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R 1 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (R 1 -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V 1 -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 9>\n",
      "SELECTED ACTION:  STAY\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 117\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (R - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 10>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 4, DOWN)\n",
      "Agent performance: 116\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (D - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 11>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 4, DOWN)\n",
      "Agent performance: 115\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (D - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 12>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 4, DOWN)\n",
      "Agent performance: 112\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (D - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (D - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 13>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 4, LEFT)\n",
      "Agent performance: 111\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (L - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(- - -) (L - -) \n",
      "(- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 14>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 3, LEFT)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (L - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (L - -) (- - -) \n",
      "(- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 15>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 2, LEFT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (L - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - 3) (L - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (- - -) (- - -) (V - -) (V - -) \n",
      "(? ? ?) (- - 3) (V - -) (V - -) (V - -) \n",
      "(? ? ?) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 16>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 1, LEFT)\n",
      "Agent performance: 101\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (L - 2) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (L - 2) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - 2) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 17>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 1, UP)\n",
      "Agent performance: 95\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (U - 1) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (U - 1) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - 1) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 18>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 1, RIGHT)\n",
      "Agent performance: 89\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (R - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (R - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 19>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (3, 1, DOWN)\n",
      "Agent performance: 88\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (D - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- - -) (D - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 20>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 1, DOWN)\n",
      "Agent performance: 87\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (D - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- 1 -) (D - -) (- - -) \n",
      "\n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 21>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 1, LEFT)\n",
      "Agent performance: 86\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (L - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) (- - -) \n",
      "(- 1 -) (L - -) (- - -) \n",
      "\n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(- 1 -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 22>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 0, LEFT)\n",
      "Agent performance: 95\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (L - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(L - -) (- - -) \n",
      "\n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 23>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 0, UP)\n",
      "Agent performance: 94\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (U - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(U - -) (- - -) \n",
      "\n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 24>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 0, UP)\n",
      "Agent performance: 93\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (U - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- - -) \n",
      "(U - -) (- - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(? ? ?) (? ? ?) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 25>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 0, UP)\n",
      "Agent performance: 92\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (U - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - 1) (- - -) \n",
      "(U - -) (- - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(? ? ?) (? ? ?) (- - -) (- - -) (- - -) \n",
      "(- - 1) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 26>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 0, UP)\n",
      "Agent performance: 86\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (U - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "(- - -) (- 1 -) \n",
      "(U - -) (- - -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 27>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 0, UP)\n",
      "Agent performance: 85\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (U - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(U - -) (- 1 -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(V - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 28>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 0, RIGHT)\n",
      "Agent performance: 84\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (R - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(R - -) (- 1 -) \n",
      "(- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(V - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 29>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 1, RIGHT)\n",
      "Agent performance: 93\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (R - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Percept\n",
      "\n",
      "(- - -) (R - -) (- - -) \n",
      "(- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(V - -) (V - -) (- - -) (- - -) (- - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (- - -) (- - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "(V - -) (V - -) (- - -) (- - -) (- - 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment = PartiallyObservableEnvironment()\n",
    "\n",
    "model_agent = ModelBasedAgent()\n",
    "environment.add_thing(model_agent)\n",
    "\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (4,0))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (0,1))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (2,3))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (1,0))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (2,3))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (4,4))\n",
    "\n",
    "# for _ in range(10):\n",
    "#     trap = Trap()\n",
    "#     environment.add_thing(trap)    \n",
    "\n",
    "# print('---------------------------')\n",
    "# print('Initial State of Environment')\n",
    "# print('---------------------------')\n",
    "# print(\"Agent state: %s\" % agent)\n",
    "# print(\"Agent performance: %s\" % agent.performance)\n",
    "# print('')\n",
    "# print('Environment:')\n",
    "# print(environment)\n",
    "\n",
    "environment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the implementation of the agents in the Partially Observable Environment we see the results of the <u>Reflex Agent's</u> performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflex_agent.performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the <u>Model-Based Agent</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_agent.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Fully Observable Environment</b></h1>\n",
    "\n",
    "In this second part of the homework we use the Fully Observable Environment, first with the Reflex Agent inside it, as well as the past exercise, we use gold and traps in explicit positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Initial State\n",
      "---------------------------\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (U - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent state: (1, 1, UP)\n",
      "Agent performance: 100\n",
      "\n",
      "---------------------------\n",
      "Run details\n",
      "---------------------------\n",
      "<STEP 1>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 1, UP)\n",
      "Agent performance: 109\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (U - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 2>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 1, RIGHT)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (R - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 3>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 2, RIGHT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (R - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 4>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 3, RIGHT)\n",
      "Agent performance: 106\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (R - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 5>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 3, DOWN)\n",
      "Agent performance: 105\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (D - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 6>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 3, DOWN)\n",
      "Agent performance: 104\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (D - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 7>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 3, DOWN)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (D - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 8>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 3, LEFT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (L - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 9>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 3, UP)\n",
      "Agent performance: 106\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (U - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 10>\n",
      "Step in visited cell\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 3, UP)\n",
      "Agent performance: 103\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (U - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 11>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 3, RIGHT)\n",
      "Agent performance: 102\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (R - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 12>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 111\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R 1 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 13>\n",
      "SELECTED ACTION:  STAY\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 121\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 14>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 4, DOWN)\n",
      "Agent performance: 120\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 15>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 4, DOWN)\n",
      "Agent performance: 119\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 16>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 4, DOWN)\n",
      "Agent performance: 118\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (D - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 17>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 4, DOWN)\n",
      "Agent performance: 112\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "<STEP 18>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 4, LEFT)\n",
      "Agent performance: 111\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (L - -) \n",
      "\n",
      "<STEP 19>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 3, LEFT)\n",
      "Agent performance: 110\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (L - -) (- - -) \n",
      "\n",
      "<STEP 20>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 2, LEFT)\n",
      "Agent performance: 109\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (L - -) (- - -) (- - -) \n",
      "\n",
      "<STEP 21>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 1, LEFT)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (L - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "<STEP 22>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 0, LEFT)\n",
      "Agent performance: 117\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (L - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment = FullyObservableEnvironment()\n",
    "\n",
    "reflex_agent = ReflexAgent()\n",
    "environment.add_thing(reflex_agent)\n",
    "\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (4,0))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (0,1))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (2,3))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (1,0))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (2,3))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (4,4))\n",
    "\n",
    "# for _ in range(10):\n",
    "#     trap = Trap()\n",
    "#     environment.add_thing(trap)    \n",
    "\n",
    "# print('---------------------------')\n",
    "# print('Initial State of Environment')\n",
    "# print('---------------------------')\n",
    "# print(\"Agent state: %s\" % agent)\n",
    "# print(\"Agent performance: %s\" % agent.performance)\n",
    "# print('')\n",
    "# print('Environment:')\n",
    "# print(environment)\n",
    "\n",
    "environment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Model Based Agent in the Fully Observable Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Initial State\n",
      "---------------------------\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (R - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent state: (2, 1, RIGHT)\n",
      "Agent performance: 100\n",
      "\n",
      "---------------------------\n",
      "Run details\n",
      "---------------------------\n",
      "<STEP 1>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 1, DOWN)\n",
      "Agent performance: 99\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (D - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 2>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 1, LEFT)\n",
      "Agent performance: 98\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (L - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 3>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 1, UP)\n",
      "Agent performance: 97\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (U - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 4>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 1, UP)\n",
      "Agent performance: 96\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (U - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (- 1 -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 5>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 1, UP)\n",
      "Agent performance: 105\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (U - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 6>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 1, RIGHT)\n",
      "Agent performance: 104\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (R - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (- - -) (- - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 7>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 2, RIGHT)\n",
      "Agent performance: 103\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (R - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (- - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 8>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (0, 3, RIGHT)\n",
      "Agent performance: 102\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (R - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 9>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (0, 3, DOWN)\n",
      "Agent performance: 101\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (D - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (- - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 10>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 3, DOWN)\n",
      "Agent performance: 100\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (D - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- 1 1) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (- 1 1) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 11>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 3, DOWN)\n",
      "Agent performance: 104\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (D - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 12>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 3, LEFT)\n",
      "Agent performance: 103\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (L - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 13>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (2, 3, UP)\n",
      "Agent performance: 102\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (U - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 14>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 3, UP)\n",
      "Agent performance: 99\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (U - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 15>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 3, RIGHT)\n",
      "Agent performance: 98\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (R - -) (- 2 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (- 2 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 16>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R 1 -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V 1 -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 17>\n",
      "SELECTED ACTION:  STAY\n",
      "Agent state:  (1, 4, RIGHT)\n",
      "Agent performance: 117\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (R - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 18>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (1, 4, DOWN)\n",
      "Agent performance: 116\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (- - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 19>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (2, 4, DOWN)\n",
      "Agent performance: 115\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 20>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (3, 4, DOWN)\n",
      "Agent performance: 114\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (D - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (- - 1) \n",
      "\n",
      "<STEP 21>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 4, DOWN)\n",
      "Agent performance: 108\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (D - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (V - -) \n",
      "\n",
      "<STEP 22>\n",
      "SELECTED ACTION:  TURN\n",
      "Agent state:  (4, 4, LEFT)\n",
      "Agent performance: 107\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (- - -) (L - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (- - -) (V - -) \n",
      "\n",
      "<STEP 23>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 3, LEFT)\n",
      "Agent performance: 106\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (- - -) (L - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (- - -) (- - -) (V - -) (V - -) \n",
      "\n",
      "<STEP 24>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 2, LEFT)\n",
      "Agent performance: 105\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (- - -) (L - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (- - -) (V - -) (V - -) (V - -) \n",
      "\n",
      "<STEP 25>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 1, LEFT)\n",
      "Agent performance: 104\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (- 1 -) (L - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(- 1 -) (V - -) (V - -) (V - -) (V - -) \n",
      "\n",
      "<STEP 26>\n",
      "SELECTED ACTION:  ADVANCE\n",
      "Agent state:  (4, 0, LEFT)\n",
      "Agent performance: 113\n",
      "\n",
      "Environment: \n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "1 (- - 1) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "2 (- - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "3 (- - -) (- - 3) (- - -) (- - -) (- - -) \n",
      "\n",
      "4 (L - -) (- - -) (- - -) (- - -) (- - -) \n",
      "\n",
      "Agent internal state\n",
      "(- - -) (V - -) (V - -) (V - -) (- - -) \n",
      "(- - 1) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (V - -) (- - -) (V - -) (V - -) \n",
      "(- - -) (- - 3) (- - -) (- - -) (V - -) \n",
      "(V - -) (V - -) (V - -) (V - -) (V - -) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment = FullyObservableEnvironment()\n",
    "\n",
    "model_agent = ModelBasedAgent()\n",
    "environment.add_thing(model_agent)\n",
    "\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (4,0))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (0,1))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (2,3))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "gold = Gold()\n",
    "environment.add_thing(gold, (1,4))\n",
    "\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (1,0))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (3,1))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (2,3))\n",
    "trap = Trap()\n",
    "environment.add_thing(trap, (4,4))\n",
    "\n",
    "# for _ in range(10):\n",
    "#     trap = Trap()\n",
    "#     environment.add_thing(trap)    \n",
    "\n",
    "# print('---------------------------')\n",
    "# print('Initial State of Environment')\n",
    "# print('---------------------------')\n",
    "# print(\"Agent state: %s\" % agent)\n",
    "# print(\"Agent performance: %s\" % agent.performance)\n",
    "# print('')\n",
    "# print('Environment:')\n",
    "# print(environment)\n",
    "\n",
    "environment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the performance of the <u>Reflex Agent</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflex_agent.performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the <u>Model Based Agent</u> in the Fully Observable Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_agent.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
